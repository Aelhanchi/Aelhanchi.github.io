---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: page
---
<img style="float: right;" src="files/pic_cropped.jpg" width="200" height="266">
I am a master's student in Mathematics and Statistics at
[McGill University](https://www.mcgill.ca/),
supervised by [David Stephens](http://www.math.mcgill.ca/dstephens/).
I completed my bachelor's degree in
[Honours Mathematics and Computer Science](https://www.mcgill.ca/mathstat/undergraduate/programs/b-sc/joint-honours-mathematics-and-computer-science-b-sc).


My research interests lie at the intersection of theory and algorithms
for machine learning and statistics, with a focus on large-scale
gradient-based optimization and sampling.


More generally, I am interested in developing the computational
and statistical tools for building systems that can make optimal
decisions under uncertainty.

[CV](files/CV.pdf) / [GitHub](https://github.com/Aelhanchi)

# Projects
+ *Memory Efficient Variance Reduced Optimization and Sampling for Deep Learning.*  
<a href="files/project_pitch.pdf">pdf</a> \| <a href="https://github.com/Aelhanchi/torch_vr">code 1</a> \| <a href="https://github.com/Aelhanchi/torch_sample">code 2</a>
+ *SGD as a two step approximation to gradient flow.*  
<a href="files/Optimization.pdf">pdf</a>
+ *Scaling up MCMC for Bayesian inference using adaptive data subsampling.*  
<a href="files/Research_project_report.pdf">pdf</a> \|
<a href="files/Research_project_presentation.pdf">slides</a>
+ *Statistical learning under a non-iid data generating process.*  
<a href="files/Statistical learning under a non-iid data generating process.pdf">pdf</a>
+ *Optimal SGLD for approximate Bayesian inference.*    
<a href="files/Optimal SGLD for Approximate Bayesian Inference.pdf">pdf</a>
